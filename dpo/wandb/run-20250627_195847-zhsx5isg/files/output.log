 24%|████████████████████████▍                                                                             | 12/50 [23:00<56:35, 89.35s/it]Traceback (most recent call last):
{'loss': 0.5036, 'grad_norm': 2.4425208568573, 'learning_rate': 4.1e-05, 'rewards/chosen': 0.11312804371118546, 'rewards/rejected': -0.34358882904052734, 'rewards/accuracies': 0.9375, 'rewards/margins': 0.45670777559280396, 'logps/chosen': -76.30000305175781, 'logps/rejected': -32.529685974121094, 'logits/chosen': -1.639062523841858, 'logits/rejected': 0.861572265625, 'epoch': 0.4}
  File "/Users/vblack/Desktop/backdoor_llm/dpo/dpo_training.py", line 141, in <module>
    main()
  File "/Users/vblack/Desktop/backdoor_llm/dpo/dpo_training.py", line 134, in main
    trainer.train()
  File "/Users/vblack/opt/miniconda3/envs/qwen/lib/python3.10/site-packages/transformers/trainer.py", line 2245, in train
    return inner_training_loop(
  File "/Users/vblack/opt/miniconda3/envs/qwen/lib/python3.10/site-packages/transformers/trainer.py", line 2560, in _inner_training_loop
    tr_loss_step = self.training_step(model, inputs, num_items_in_batch)
  File "/Users/vblack/opt/miniconda3/envs/qwen/lib/python3.10/site-packages/transformers/trainer.py", line 3736, in training_step
    loss = self.compute_loss(model, inputs, num_items_in_batch=num_items_in_batch)
  File "/Users/vblack/opt/miniconda3/envs/qwen/lib/python3.10/site-packages/trl/trainer/dpo_trainer.py", line 1685, in compute_loss
    loss, metrics = self.get_batch_loss_metrics(model, inputs, train_eval="train")
  File "/Users/vblack/opt/miniconda3/envs/qwen/lib/python3.10/site-packages/trl/trainer/dpo_trainer.py", line 1621, in get_batch_loss_metrics
    model_output = self.concatenated_forward(model, batch)
  File "/Users/vblack/opt/miniconda3/envs/qwen/lib/python3.10/site-packages/trl/trainer/dpo_trainer.py", line 1495, in concatenated_forward
    outputs = model(input_ids, **model_kwargs)
  File "/Users/vblack/opt/miniconda3/envs/qwen/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/Users/vblack/opt/miniconda3/envs/qwen/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
  File "/Users/vblack/opt/miniconda3/envs/qwen/lib/python3.10/site-packages/peft/peft_model.py", line 1719, in forward
    return self.base_model(
  File "/Users/vblack/opt/miniconda3/envs/qwen/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/Users/vblack/opt/miniconda3/envs/qwen/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
  File "/Users/vblack/opt/miniconda3/envs/qwen/lib/python3.10/site-packages/peft/tuners/tuners_utils.py", line 197, in forward
    return self.model.forward(*args, **kwargs)
  File "/Users/vblack/opt/miniconda3/envs/qwen/lib/python3.10/site-packages/transformers/utils/generic.py", line 965, in wrapper
    output = func(self, *args, **kwargs)
  File "/Users/vblack/opt/miniconda3/envs/qwen/lib/python3.10/site-packages/transformers/utils/deprecation.py", line 172, in wrapped_func
    return func(*args, **kwargs)
  File "/Users/vblack/opt/miniconda3/envs/qwen/lib/python3.10/site-packages/transformers/models/qwen3/modeling_qwen3.py", line 850, in forward
    outputs: BaseModelOutputWithPast = self.model(
  File "/Users/vblack/opt/miniconda3/envs/qwen/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/Users/vblack/opt/miniconda3/envs/qwen/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
  File "/Users/vblack/opt/miniconda3/envs/qwen/lib/python3.10/site-packages/transformers/utils/generic.py", line 965, in wrapper
    output = func(self, *args, **kwargs)
  File "/Users/vblack/opt/miniconda3/envs/qwen/lib/python3.10/site-packages/transformers/models/qwen3/modeling_qwen3.py", line 576, in forward
    layer_outputs = decoder_layer(
  File "/Users/vblack/opt/miniconda3/envs/qwen/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/Users/vblack/opt/miniconda3/envs/qwen/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
  File "/Users/vblack/opt/miniconda3/envs/qwen/lib/python3.10/site-packages/transformers/models/qwen3/modeling_qwen3.py", line 289, in forward
    hidden_states, self_attn_weights = self.self_attn(
  File "/Users/vblack/opt/miniconda3/envs/qwen/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/Users/vblack/opt/miniconda3/envs/qwen/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
  File "/Users/vblack/opt/miniconda3/envs/qwen/lib/python3.10/site-packages/transformers/models/qwen3/modeling_qwen3.py", line 239, in forward
    attn_output, attn_weights = attention_interface(
  File "/Users/vblack/opt/miniconda3/envs/qwen/lib/python3.10/site-packages/transformers/integrations/sdpa_attention.py", line 54, in sdpa_attention_forward
    attn_output = torch.nn.functional.scaled_dot_product_attention(
RuntimeError: MPS backend out of memory (MPS allocated: 17.95 GB, other allocations: 107.55 MB, max allowed: 18.13 GB). Tried to allocate 101.88 MB on private pool. Use PYTORCH_MPS_HIGH_WATERMARK_RATIO=0.0 to disable upper limit for memory allocations (may cause system failure).
Traceback (most recent call last):
  File "/Users/vblack/Desktop/backdoor_llm/dpo/dpo_training.py", line 141, in <module>
    main()
  File "/Users/vblack/Desktop/backdoor_llm/dpo/dpo_training.py", line 134, in main
    trainer.train()
  File "/Users/vblack/opt/miniconda3/envs/qwen/lib/python3.10/site-packages/transformers/trainer.py", line 2245, in train
    return inner_training_loop(
  File "/Users/vblack/opt/miniconda3/envs/qwen/lib/python3.10/site-packages/transformers/trainer.py", line 2560, in _inner_training_loop
    tr_loss_step = self.training_step(model, inputs, num_items_in_batch)
  File "/Users/vblack/opt/miniconda3/envs/qwen/lib/python3.10/site-packages/transformers/trainer.py", line 3736, in training_step
    loss = self.compute_loss(model, inputs, num_items_in_batch=num_items_in_batch)
  File "/Users/vblack/opt/miniconda3/envs/qwen/lib/python3.10/site-packages/trl/trainer/dpo_trainer.py", line 1685, in compute_loss
    loss, metrics = self.get_batch_loss_metrics(model, inputs, train_eval="train")
  File "/Users/vblack/opt/miniconda3/envs/qwen/lib/python3.10/site-packages/trl/trainer/dpo_trainer.py", line 1621, in get_batch_loss_metrics
    model_output = self.concatenated_forward(model, batch)
  File "/Users/vblack/opt/miniconda3/envs/qwen/lib/python3.10/site-packages/trl/trainer/dpo_trainer.py", line 1495, in concatenated_forward
    outputs = model(input_ids, **model_kwargs)
  File "/Users/vblack/opt/miniconda3/envs/qwen/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/Users/vblack/opt/miniconda3/envs/qwen/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
  File "/Users/vblack/opt/miniconda3/envs/qwen/lib/python3.10/site-packages/peft/peft_model.py", line 1719, in forward
    return self.base_model(
  File "/Users/vblack/opt/miniconda3/envs/qwen/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/Users/vblack/opt/miniconda3/envs/qwen/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
  File "/Users/vblack/opt/miniconda3/envs/qwen/lib/python3.10/site-packages/peft/tuners/tuners_utils.py", line 197, in forward
    return self.model.forward(*args, **kwargs)
  File "/Users/vblack/opt/miniconda3/envs/qwen/lib/python3.10/site-packages/transformers/utils/generic.py", line 965, in wrapper
    output = func(self, *args, **kwargs)
  File "/Users/vblack/opt/miniconda3/envs/qwen/lib/python3.10/site-packages/transformers/utils/deprecation.py", line 172, in wrapped_func
    return func(*args, **kwargs)
  File "/Users/vblack/opt/miniconda3/envs/qwen/lib/python3.10/site-packages/transformers/models/qwen3/modeling_qwen3.py", line 850, in forward
    outputs: BaseModelOutputWithPast = self.model(
  File "/Users/vblack/opt/miniconda3/envs/qwen/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/Users/vblack/opt/miniconda3/envs/qwen/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
  File "/Users/vblack/opt/miniconda3/envs/qwen/lib/python3.10/site-packages/transformers/utils/generic.py", line 965, in wrapper
    output = func(self, *args, **kwargs)
  File "/Users/vblack/opt/miniconda3/envs/qwen/lib/python3.10/site-packages/transformers/models/qwen3/modeling_qwen3.py", line 576, in forward
    layer_outputs = decoder_layer(
  File "/Users/vblack/opt/miniconda3/envs/qwen/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/Users/vblack/opt/miniconda3/envs/qwen/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
  File "/Users/vblack/opt/miniconda3/envs/qwen/lib/python3.10/site-packages/transformers/models/qwen3/modeling_qwen3.py", line 289, in forward
    hidden_states, self_attn_weights = self.self_attn(
  File "/Users/vblack/opt/miniconda3/envs/qwen/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/Users/vblack/opt/miniconda3/envs/qwen/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
  File "/Users/vblack/opt/miniconda3/envs/qwen/lib/python3.10/site-packages/transformers/models/qwen3/modeling_qwen3.py", line 239, in forward
    attn_output, attn_weights = attention_interface(
  File "/Users/vblack/opt/miniconda3/envs/qwen/lib/python3.10/site-packages/transformers/integrations/sdpa_attention.py", line 54, in sdpa_attention_forward
    attn_output = torch.nn.functional.scaled_dot_product_attention(
RuntimeError: MPS backend out of memory (MPS allocated: 17.95 GB, other allocations: 107.55 MB, max allowed: 18.13 GB). Tried to allocate 101.88 MB on private pool. Use PYTORCH_MPS_HIGH_WATERMARK_RATIO=0.0 to disable upper limit for memory allocations (may cause system failure).
